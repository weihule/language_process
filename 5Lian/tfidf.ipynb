{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf\n",
    "\n",
    "英文全称： term frequency-inverse document frequency\n",
    "\n",
    "tf-idf是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。它是一种用于信息检索与文本挖掘的常用加权技术。\n",
    "$$\n",
    "tf-idf = tf * idf\n",
    "\t\t \n",
    "$$\n",
    "\n",
    "\n",
    "其中：\n",
    "$$\n",
    "tf = \\frac{n}{N} , 即 词频 = \\frac{词语在文本中出现的次数}{文本中总词语数目}\n",
    "$$\n",
    "\n",
    "$$\n",
    "idf = log\\frac{D}{d}, 即 逆向文档频率 = log\\frac{总的文档数}{词语所在的文档数}\n",
    "$$\n",
    "对于每个词语来说，总的文档数D都是一样的，只是会出现的不同数量的文档里，如果一个词语出现在多个文档里，idf会变小。如此，tf-idf的值会随着tf的增大而正比增大，但随着它在更多文档中出现而下降。\n",
    "\n",
    "举一个简单的例子：\n",
    "\n",
    "假设有一个文本:\n",
    "\n",
    "```python\n",
    "train = ['Chinese Beijing Chinese',\n",
    "         'Chinese Chinese Shanghai',\n",
    "         'Chinese Macao',\n",
    "         'Tokyo Tapan Chinese']\n",
    "```\n",
    "\n",
    "按照特征 `['beijing' 'chinese' 'macao' 'shanghai' 'tapan' 'tokyo']` 计算第一行文本信息的tf-idf值，输出矩阵如下：\n",
    "```python\n",
    "[[0.6931471805599453, 0, ...],\n",
    " [...], ...]\n",
    "```\n",
    "第一行中，词语 \"beijing\" 出现了1次，总词语数目为3。那么词语 \"beijing\" 的TF为：\n",
    "\n",
    "TF(\"beijing\") = 1 / 3 = 0.33333333333\n",
    "\n",
    "总的文本行是4, 'beijing'只在第一个文本行出现过, 所以\n",
    "\n",
    "IDF(\"beijing\") = log(4 / 1) = 1.3862943611198906\n",
    "\n",
    "最终，TF-IDF(\"beijing\") = 0.33333333333 * 1.3862943611198906\n",
    "\n",
    "同样，计算第一行中'chinese'的tf-idf值\n",
    "TF('chinese') = 2 / 3 = 0.66666666667\n",
    "IDF('chinese') = log(4 / 4) = 0\n",
    "TF-IDF('chinese') = 0\n",
    "\n",
    "\n",
    "**不足：**\n",
    "\n",
    "- 频率越小单词约重要？\n",
    "\n",
    "- 单词频率越大就越无用？\n",
    "\n",
    "- 不能体现上下文信息？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing' 'chinese' 'macao' 'shanghai' 'tapan' 'tokyo']\n",
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 1 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 0 0 1 1]]\n",
      "[[0.48931268 0.51068732 0.         0.         0.         0.        ]\n",
      " [0.         0.51068732 0.         0.48931268 0.         0.        ]\n",
      " [0.         0.34290134 0.65709866 0.         0.         0.        ]\n",
      " [0.         0.20692874 0.         0.         0.39653563 0.39653563]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "train = ['Chinese Beijing Chinese',\n",
    "         'Chinese Chinese Shanghai',\n",
    "         'Chinese Macao',\n",
    "         'Tokyo Tapan Chinese']\n",
    "\n",
    "# 计算词频矩阵\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_counts = count_vectorizer.fit_transform(train)\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "print(train_counts.toarray())\n",
    "\n",
    "# 创建TfidfTransformer对象\n",
    "transformer = TfidfTransformer(norm='l1')\n",
    "tfidf_matrix = transformer.fit_transform(train_counts)\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn-tf-idf\n",
    "\n",
    "在sklearn中，$ tf = n $，并未直接做归一化；$ idf = log\\frac{D+1}{d+1} + 1 $，对分母和分子做了平滑处理，这样为了分母不为零。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## norm 设置为None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing' 'chinese' 'macao' 'shanghai' 'tapan' 'tokyo']\n",
      "[[1.91629073 2.         0.         0.         0.         0.        ]\n",
      " [0.         2.         0.         1.91629073 0.         0.        ]\n",
      " [0.         1.         1.91629073 0.         0.         0.        ]\n",
      " [0.         1.         0.         0.         1.91629073 1.91629073]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "tv = TfidfVectorizer(use_idf=True, smooth_idf=True, norm=None)\n",
    "\n",
    "# 输入训练集矩阵，每行表示一个文本\n",
    "train = ['Chinese Beijing Chinese',\n",
    "         'Chinese Chinese Shanghai',\n",
    "         'Chinese Macao',\n",
    "         'Tokyo Tapan Chinese']\n",
    "\n",
    "# 训练，构建词汇表以及词项idf值，并将文本列表转成VSM矩阵格式\n",
    "tv_fit = tv.fit_transform(train)\n",
    "\n",
    "# 查看构建的词汇表\n",
    "print(tv.get_feature_names_out())\n",
    "\n",
    "# 将稀疏矩阵转换为稠密矩阵\n",
    "arrs = tv_fit.toarray()\n",
    "print(arrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释下上述值是怎么计算出来的，以第一行为例\n",
    "'beijing' 在第一行中出现了一次，所以\n",
    "TF('beijing') = 1\n",
    "总的文本行是4个，'beijing'只在第一行出现，所以\n",
    "IDF('beijing') = log((4+1) / (1+1)) + 1 = log(5/2) + 1 = 1.916290731874155\n",
    "TF-IDF('beijing') = 1 * 1.916290731874155\n",
    "\n",
    "TF('chinese') = 2\n",
    "IDF('chinese') = log((4+1) / (4+1)) + 1 = log(1) + 1 = 1\n",
    "TF-IDF('chinese') = 2 * 1 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## norm 为l1归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing' 'chinese' 'macao' 'shanghai' 'tapan' 'tokyo']\n",
      "[[0.48931268 0.51068732 0.         0.         0.         0.        ]\n",
      " [0.         0.51068732 0.         0.48931268 0.         0.        ]\n",
      " [0.         0.34290134 0.65709866 0.         0.         0.        ]\n",
      " [0.         0.20692874 0.         0.         0.39653563 0.39653563]]\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(use_idf=True, smooth_idf=True, norm='l1')\n",
    "\n",
    "# 输入训练集矩阵，每行表示一个文本\n",
    "train = ['Chinese Beijing Chinese',\n",
    "         'Chinese Chinese Shanghai',\n",
    "         'Chinese Macao',\n",
    "         'Tokyo Tapan Chinese']\n",
    "\n",
    "# 训练，构建词汇表以及词项idf值，并将文本列表转成VSM矩阵格式\n",
    "tv_fit = tv.fit_transform(train)\n",
    "\n",
    "# 查看构建的词汇表\n",
    "print(tv.get_feature_names_out())\n",
    "\n",
    "arrs = tv_fit.toarray()\n",
    "print(arrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的0.48931268 = 1.91629073 / sum(1.91629073, 2, 0, 0, 0, 0) \n",
    "另外可以看到，每一行的相加和为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## norm 为l2归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing' 'chinese' 'macao' 'shanghai' 'tapan' 'tokyo']\n",
      "[[0.69183461 0.722056   0.         0.         0.         0.        ]\n",
      " [0.         0.722056   0.         0.69183461 0.         0.        ]\n",
      " [0.         0.46263733 0.88654763 0.         0.         0.        ]\n",
      " [0.         0.34618161 0.         0.         0.66338461 0.66338461]]\n",
      "[[0.47863513 0.52136487 0.         0.         0.         0.        ]\n",
      " [0.         0.52136487 0.         0.47863513 0.         0.        ]\n",
      " [0.         0.2140333  0.7859667  0.         0.         0.        ]\n",
      " [0.         0.11984171 0.         0.         0.44007915 0.44007915]]\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(use_idf=True, smooth_idf=True, norm='l2')\n",
    "\n",
    "# 输入训练集矩阵，每行表示一个文本\n",
    "train = ['Chinese Beijing Chinese',\n",
    "         'Chinese Chinese Shanghai',\n",
    "         'Chinese Macao',\n",
    "         'Tokyo Tapan Chinese']\n",
    "\n",
    "# 训练，构建词汇表以及词项idf值，并将文本列表转成VSM矩阵格式\n",
    "tv_fit = tv.fit_transform(train)\n",
    "\n",
    "# 查看构建的词汇表\n",
    "print(tv.get_feature_names_out())\n",
    "\n",
    "arrs = tv_fit.toarray()\n",
    "print(arrs)\n",
    "arrs = np.power(arrs, 2)\n",
    "print(arrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，l2归一化的平方和相加为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
